{"cells":[{"cell_type":"markdown","metadata":{"id":"4At5N8U7WD55"},"source":["# Finetuning script for Cross-encoder\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iom47VL-UCQo"},"outputs":[],"source":["# Installing Sentence Transformers for Cross Encoder and Importing other Dependencies\n","!pip install -U sentence-transformers\n","!pip install gdown\n","import gdown\n","import numpy as np\n","import pandas as pd\n","import os\n","import json\n","import random\n","from torch.utils.data import DataLoader\n","import math\n","from sentence_transformers import LoggingHandler, util\n","from sentence_transformers.cross_encoder import CrossEncoder\n","from sentence_transformers.cross_encoder.evaluation import CECorrelationEvaluator\n","from sentence_transformers import InputExample\n","import logging\n","from datetime import datetime\n","import sys\n","from ast import literal_eval\n","import os\n","import gzip\n","import csv\n","from tqdm import tqdm"]},{"cell_type":"markdown","metadata":{"id":"_yUQPoKI1LJr"},"source":["#Data Extraction and Pre-Processing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BAcHsUYJamde"},"outputs":[],"source":["# Download training files using gdown\n","cwd = os.getcwd()\n","url = \"https://drive.google.com/u/1/uc?id=1jHR-T1PH4xkd4ljGWn8lD-HaJPYMo4EC&export=download\" #> Provided training data\n","output = cwd+\"/train_data.csv\"\n","gdown.download(url, output, quiet=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XKzaM9-HZGVN"},"outputs":[],"source":["# Path for Training Data File\n","data_path = './train_data.csv'\n","\n","# Split Ratio for Training and Validation and Test\n","split = [80, 10, 10]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9oDwTbFRbnka"},"outputs":[],"source":["# Reading data for finetuning\n","\n","full_data = pd.read_csv(data_path)\n","themes = full_data.Theme.unique()\n","full_data.Answer_start = full_data.Answer_start.apply(literal_eval)\n","full_data.Answer_text = full_data.Answer_text.apply(literal_eval)\n","full_data['Unnamed: 0'] = full_data['Unnamed: 0'].astype(str)\n","train_samples = []\n","val_samples = []\n","test_samples = []\n","\n","# Divide the complete data into training and validation and\n","# testing data in the defined split ratio for each theme.\n","\n","for theme in themes:\n","  theme_df = full_data[full_data['Theme']==theme]\n","  n = len(theme_df)\n","  for i,theme_row in enumerate(theme_df.iterrows()):\n","    theme_row = theme_row[1]\n","    input = {\n","              'Answer_start': theme_row['Answer_start'],\n","              'Answer_text':theme_row['Answer_text'],\n","              'Paragraph':theme_row['Paragraph'],\n","              'id':theme_row['Unnamed: 0'],\n","              'Question': theme_row['Question'],\n","              'Theme': theme_row['Theme'],\n","              'Answer_possible': theme_row['Answer_possible']\n","          }\n","    if i<int(split[0]*n/sum(split)):\n","      train_samples.append(input)\n","    elif i<int((split[0]+split[1])*n/sum(split)):\n","      val_samples.append(input)\n","    else:\n","      test_samples.append(input)\n","train_df = pd.DataFrame(train_samples)\n","val_df = pd.DataFrame(val_samples)\n","test_df = pd.DataFrame(test_samples)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZtywwNI5plfl"},"outputs":[],"source":["# Converting the given data in the MS-MARCO dataset format for Cross Encoder \n","# fine-tuning.\n","\n","def preprocess_data(df):\n","  data = []\n","  for i in tqdm(range(len(df))):\n","    data_dict = dict()\n","    question = df.Question.iloc[i]\n","    true_para = df.Paragraph.iloc[i]\n","    all_para = df[df.Theme==df.Theme.iloc[i]].Paragraph.unique().tolist()\n","    all_para.remove(true_para)\n","    random.shuffle(all_para)\n","    if len(all_para) >= 10:\n","        took_para = all_para[:10]\n","    else:\n","        took_para = all_para\n","    rand_index = random.randint(0,len(took_para)-1)\n","    is_selected = [0]*len(took_para)\n","    if df.Answer_possible.iloc[i] or df.Answer_possible.iloc[i]=='TRUE':\n","        is_selected[rand_index] = 1\n","    took_para[rand_index] = true_para\n","    data_dict['query'] = question\n","    data_dict['passages'] = {'is_selected': is_selected, 'passage_text': took_para}\n","    data_dict['answer'] = df.Answer_text.iloc[i]\n","    data.append(data_dict)\n","  return pd.DataFrame(data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d7a-PkH2rDZQ"},"outputs":[],"source":["train_df = preprocess_data(train_df) #pre-process for training split\n","val_df = preprocess_data(val_df) #pre-process for validation split\n","#test_df = preprocess_data(test_df) #pre-process for testing split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ht-vPb0dt06D"},"outputs":[],"source":["# Adds Preprocessed data in train_samples, val_samples with labels\n","# if Question and Paragraph pair are matching then label is 1\n","# else label is 0\n","train_samples = []\n","val_samples = []\n","\n","for i in range(len(train_df)):\n","    query = train_df.loc[i, 'query']\n","    contexts = train_df.loc[i, 'passages']['passage_text']\n","    select_idx = -1\n","    if 1 in train_df.loc[i, 'passages']['is_selected']:\n","      select_idx = train_df.loc[i, 'passages']['is_selected'].index(1)\n","    for j in range(len(contexts)):\n","        if j==select_idx:\n","            train_samples.append(InputExample(texts=[query, contexts[j]], label=1))\n","        else:\n","            train_samples.append(InputExample(texts=[query, contexts[j]], label=0))\n","\n","for i in range(len(val_df)):\n","    query = val_df.loc[i, 'query']\n","    contexts = val_df.loc[i, 'passages']['passage_text']\n","    select_idx = -1\n","    if 1 in train_df.loc[i, 'passages']['is_selected']:\n","      select_idx = train_df.loc[i, 'passages']['is_selected'].index(1)\n","    for j in range(len(contexts)):\n","        if j==select_idx:\n","            val_samples.append(InputExample(texts=[query, contexts[j]], label=1))\n","        else:\n","            val_samples.append(InputExample(texts=[query, contexts[j]], label=0))"]},{"cell_type":"markdown","metadata":{"id":"Ub20YG_EWIHa"},"source":["#Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wTtdJnxjWQXr"},"outputs":[],"source":["#loads the Base Cross-Encoder MiniLM-L-4-v2 from Huggingface Library\n","model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-4-v2', num_labels=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zunYEXXCWZbP"},"outputs":[],"source":["# Finetuning configurations\n","train_batch_size = 16\n","num_epochs = 4\n","train_dataloader = DataLoader(train_samples, shuffle=True, batch_size=train_batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IkkNRjBWWrY1"},"outputs":[],"source":["# Evaluator methods\n","evaluator = CECorrelationEvaluator.from_input_examples(val_samples, name='val') #Evaluation with validation dataset\n","warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1) #10% of train data for warm-up\n","model.fit(train_dataloader=train_dataloader,evaluator=evaluator,epochs=num_epochs,warmup_steps=warmup_steps,output_path='./minilml4-v2')"]}],"metadata":{"colab":{"provenance":[],"private_outputs":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}