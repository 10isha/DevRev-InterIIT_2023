{"cells":[{"cell_type":"markdown","metadata":{"id":"8K1Hw_hO3NCR"},"source":["# Finetuning QA model\n","\n","User-defined fine-tuning parameters in variables:\n","\n","1. **qa_model**: name of the model to finetune. Change only when you want to fine tune a particular model checkpoint.\n","\n","2. **data_path**: the data csv upon which training/validation is required to be done.\n","\n","3. **data_path_eval**: the data csv to evaluate the checkpoint in save_path_eval\n","\n","4. **save_path**: the path to save the checkpoints during finetune.\n","\n","5. **save_path_eval**: the path containing checkpoints to evaluate\n","\n","6. **batch_size**: Batch size for finetuning. default=32\n","\n","7. **split**: split of train, validate and test of data_path csv for finetuning\n","\n","8. **mode**: set to different modes namely- finetune+eval on same data('ft+eval_same'), finetune+eval on different data('ft+eval_custom') and evaluation only to evaluate checkpoints on a particular data('eval_only').\n","\n","## FOR FINETUNE AND VAL BOTH('ft+eval_same', 'ft+eval_custom'):\n","\n","  File Generation and preprocessing---> Imports ----> Variables(set required mode-'ft+eval_same' or'ft+eval_custom')---->FineTuning---->Validation csv Generation---> 4 csv generation---> QA evaluation\n","\n","## FOR VAL only ('eval_only'):\n","\n","  File Generation and preprocessing---> Imports ----> Variables(set required mode-'eval_only')---->Validation csv Generation---> 4 csv generation---> QA evaluation\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"JJGmY-7m_G7P"},"source":["## File Generation and Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LWuajsLM4XZM"},"outputs":[],"source":["import os\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kuV_Feps_Szu"},"outputs":[],"source":["'''\n","The 'para_data' and 'question_ans' variables take the files provided in the \n","first stage of evaluation, i.e., in morning\n","'''\n","\n","\n","import pandas as pd\n","# Paragraph mapping file\n","para_data = pd.read_csv('https://drive.google.com/uc?export=download&id=1GNHhH81J1pEZSB-OSGRTtqIUQCCNhJ6I')\n","# Questions mapping file\n","question_ans = pd.read_csv('https://drive.google.com/uc?export=download&id=1GQ3-E7k60K16f47A18ptQfKUBkhxQudM')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D8qF9Ioz61Ec"},"outputs":[],"source":["df = question_ans\n","df2 = para_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hyv8fUPX7PoM"},"outputs":[],"source":["para_id_list = df.paragraph_id.tolist()\n","paras = []\n","for i in para_id_list:\n","    paras.append(df2['paragraph'][df2.id==i].tolist()[0])\n","df['paragraph'] = paras\n","df.rename(columns = {'question':'Question', 'theme':'Theme','answer':'Answer_text', 'paragraph':'Paragraph'}, inplace = True)\n","poss = []\n","for i in range(len(df)):\n","    poss.append('TRUE')\n","df['Answer_possible'] = poss\n","start = []\n","for i in range(len(df)):\n","  # print(df['Answer_text'][i])\n","  s = str(df['Answer_text'][i])\n","  start.append([df['Paragraph'][i].find(s)])\n","df['Answer_start'] = start\n","answers = df['Answer_text'].tolist()\n","ans = []\n","for i in answers:\n","    ans.append([i])\n","df['Answer_text'] = ans\n","df.to_csv('/content/finaldataprocessed.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZdTWYqhJJw7k"},"outputs":[],"source":["csv_save_path='/content/finaldataprocessed.csv'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bk2443j88Syv"},"outputs":[],"source":["df = pd.read_csv(csv_save_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TXtIEkukB65U"},"outputs":[],"source":["df = df.rename(columns={'Unnamed: 0':'id'})\n","df['id'] =df['id']+1\n","df.to_csv('/content/finaldataprocessed.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IfdA7xYtCtc8"},"outputs":[],"source":["if not os.path.exists('/content/Final_data'): os.mkdir('/content/Final_data')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yZzc3lPn_oW5"},"outputs":[],"source":["m='/content/Final_data'\n","df = pd.read_csv('/content/finaldataprocessed.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3StDoV14CrOe"},"outputs":[],"source":["paras = df.Paragraph.unique()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XxCRe4L9UT2f"},"outputs":[],"source":["df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"007AokzvUWSb"},"outputs":[],"source":["df.columns"]},{"cell_type":"markdown","metadata":{"id":"IQ1u-0zgeoiC"},"source":["## Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-wHp-oFHerKU"},"outputs":[],"source":["# Install the Transformers, Datasets, and Evaluate libraries to run this notebook.\n","!pip install datasets evaluate transformers[sentencepiece]\n","!pip install accelerate\n","\n","import torch\n","import pandas as pd\n","from transformers import AutoModelForQuestionAnswering\n","import collections\n","import evaluate\n","from tqdm.auto import tqdm\n","import datasets\n","from transformers import AutoTokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ujoMOFgE8OCt"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-xVJUuk5Fe_l"},"outputs":[],"source":["!pip install gdown"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5SUS7KUvFjxQ"},"outputs":[],"source":["import gdown\n","\n","url = \"https://drive.google.com/uc?export=download&id=19dxbN5KR2O0eVA4XA76PVD5HJVszm3Nk\"\n","output = \"synth_data_stage1.csv\"\n","gdown.download(url, output)"]},{"cell_type":"markdown","metadata":{"id":"VAim9LD1LrKu"},"source":["## Variables"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Ow3NxpiH2Qe"},"outputs":[],"source":["#mode: 'ft+eval_same', 'ft+eval_custom', 'eval_only\n","\n","\n","mode='eval_only'\n","data_path = ''\n","split = [80, 20, 0]\n","\n","if(mode=='ft+eval_same'):\n","  #qa model to finetune and evaluate\n","  qa_model = 'mrm8488/electra-small-finetuned-squadv2'\n","  #dataset to finetune\n","  data_path = csv_save_path\n","  #split the dataset \n","  split_ft = [80,20,0]\n","  split = split_ft\n","  # Checkpoints save_path for saving model checkpoints during fine tuning\n","  save_path = 'electra-small-finetuned-stage1_'\n","  # checkpoints path for evaluation\n","\n","elif (mode=='ft+eval_custom'):\n","  #qa model to finetune/evaluate\n","  qa_model = 'mrm8488/electra-small-finetuned-squadv2'\n","  #dataset to finetune\n","  data_path = csv_save_path\n","  #dataset to evaluate \n","  data_path_eval='synth_data_stage1.csv'\n","  #split the dataset \n","  split_ft = [80,20,0]\n","  split = split_ft\n","  split_eval=[0,100,0]\n","  # Checkpoints save_path for model checkpoints for fine tuning\n","  save_path = 'electra-small-finetuned-stage1_'\n","  # checkpoints path for evaluation\n","  save_path_eval = 'electra-small-finetuned-stage1_'\n","  # This path should have one or more folders containing model checkpoints\n","elif( mode=='eval_only'):\n","  #qa model to evaluate\n","  qa_model = 'mrm8488/electra-small-finetuned-squadv2'\n","  #dataset to evaluate \n","  data_path_eval='synth_data_stage1.csv'\n","  data_path = data_path_eval\n","  split_eval=[0,100,0] #default----don't change if you want to validate whole of your data\n","  # checkpoints path for evaluation\n","  # save_path_eval = '/content/drive/MyDrive/Assets/Finetuned-QA/electra-small-finetuned-stage1_Abhijitbatch_size_32'\n","  save_path_eval = 'electra-small-finetuned-stage1_'\n","  # This path should have one or more folders containing model checkpoints\n","\n","batch_size=32\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vFGj6USVFi33"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"Dz5a0nvgae1n"},"source":["## Fine Tuning (To be run only during fine tune)"]},{"cell_type":"markdown","metadata":{"id":"6ePrJiCIdyVm"},"source":["### Helpers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YOOhxcfkd1BK"},"outputs":[],"source":["#preprocess the validation examples\n","def preprocess_validation_examples(examples):  \n","    questions = [q.strip() for q in examples[\"question\"]]\n","    inputs = tokenizer(\n","        questions,\n","        examples[\"context\"],\n","        max_length=max_length,\n","        truncation=\"only_second\",\n","        stride=stride,\n","        return_overflowing_tokens=True,\n","        return_offsets_mapping=True,\n","        padding=\"max_length\",\n","    )\n","\n","    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n","    example_ids = []\n","\n","    for i in range(len(inputs[\"input_ids\"])):\n","        sample_idx = sample_map[i]\n","        example_ids.append(examples[\"id\"][sample_idx])\n","\n","        sequence_ids = inputs.sequence_ids(i)\n","        offset = inputs[\"offset_mapping\"][i]\n","        inputs[\"offset_mapping\"][i] = [\n","            o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n","        ]\n","\n","    inputs[\"example_id\"] = example_ids\n","    return inputs\n","#Preprocessing the training examples\n","def preprocess_training_examples(examples):\n","    questions = [q.strip() for q in examples[\"question\"]]\n","    inputs = tokenizer(\n","        questions,\n","        examples[\"context\"],\n","        max_length=max_length,\n","        truncation=\"only_second\",\n","        stride=stride,\n","        return_overflowing_tokens=True,\n","        return_offsets_mapping=True,\n","        padding=\"max_length\",\n","    )\n","\n","    offset_mapping = inputs.pop(\"offset_mapping\")\n","    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n","    answers = examples[\"answers\"]\n","    start_positions = []\n","    end_positions = []\n","\n","    for i, offset in enumerate(offset_mapping):\n","        sample_idx = sample_map[i]\n","        answer = answers[sample_idx]\n","        if len(answer['answer_start'])==0:\n","          start_positions.append(0)\n","          end_positions.append(0)\n","        else:\n","          start_char = answer[\"answer_start\"][0]\n","          end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n","          sequence_ids = inputs.sequence_ids(i)\n","\n","          # Find the start and end of the context\n","          idx = 0\n","          while sequence_ids[idx] != 1:\n","              idx += 1\n","          context_start = idx\n","          while sequence_ids[idx] == 1:\n","              idx += 1\n","          context_end = idx - 1\n","\n","          # If the answer is not fully inside the context, label is (0, 0)\n","          if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n","              start_positions.append(0)\n","              end_positions.append(0)\n","          else:\n","              # Otherwise it's the start and end token positions\n","              idx = context_start\n","              while idx <= context_end and offset[idx][0] <= start_char:\n","                  idx += 1\n","              start_positions.append(idx - 1)\n","\n","              idx = context_end\n","              while idx >= context_start and offset[idx][1] >= end_char:\n","                  idx -= 1\n","              end_positions.append(idx + 1)\n","\n","    inputs[\"start_positions\"] = start_positions\n","    inputs[\"end_positions\"] = end_positions\n","    return inputs\n","\n","#To compute the metrics for question answering transformer frameworks\n","def compute_metrics(start_logits, end_logits, features, examples):\n","    example_to_features = collections.defaultdict(list)\n","    for idx, feature in enumerate(features):\n","        example_to_features[feature[\"example_id\"]].append(idx)\n","\n","    predicted_answers = []\n","    for example in tqdm(examples):\n","        example_id = example[\"id\"]\n","        context = example[\"context\"]\n","        answers = []\n","\n","        # Loop through all features associated with that example\n","        for feature_index in example_to_features[example_id]:\n","            start_logit = start_logits[feature_index]\n","            end_logit = end_logits[feature_index]\n","            offsets = features[feature_index][\"offset_mapping\"]\n","\n","            start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()\n","            end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()\n","            for start_index in start_indexes:\n","                for end_index in end_indexes:\n","                    # Skip answers that are not fully in the context\n","                    if offsets[start_index] is None or offsets[end_index] is None:\n","                        continue\n","                    # Skip answers with a length that is either < 0 or > max_answer_length\n","                    if (\n","                        end_index < start_index\n","                        or end_index - start_index + 1 > max_answer_length\n","                    ):\n","                        continue\n","\n","                    answer = {\n","                        \"text\": context[offsets[start_index][0] : offsets[end_index][1]],\n","                        \"logit_score\": start_logit[start_index] + end_logit[end_index],\n","                    }\n","                    answers.append(answer)\n","\n","        # Select the answer with the best score\n","        if len(answers) > 0:\n","            best_answer = max(answers, key=lambda x: x[\"logit_score\"])\n","            score_null = start_logits[0][0] + end_logits[0][0]\n","            score_diff = score_null-best_answer[\"logit_score\"]\n","            predicted_answers.append(\n","                {\"id\": example_id, \"prediction_text\": best_answer[\"text\"],'no_answer_probability':score_diff}\n","            )\n","        else:\n","            predicted_answers.append({\"id\": example_id, \"prediction_text\": \"\"})\n","\n","    theoretical_answers = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in examples]\n","    return metric.compute(predictions=predicted_answers, references=theoretical_answers)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uzLhfstteXWQ"},"outputs":[],"source":["#load the model and the respective tokenizer from the checkpoint link in variable qa_model\n","\n","model_checkpoint = qa_model\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n","tokenizer.is_fast"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q5dPbdDZjqW4"},"outputs":[],"source":["#split the dataset according to the variable split. Default split=[80, 10, 10]---(train, validation, test)\n","\n","from ast import literal_eval\n","\n","full_data = pd.read_csv(data_path)\n","id = []\n","for i in range(len(full_data)):\n","  id.append(i)\n","full_data['Unnamed: 0']=id\n","themes = full_data.Theme.unique()\n","full_data.Answer_start = full_data.Answer_start.apply(literal_eval)\n","full_data.Answer_text = full_data.Answer_text.apply(literal_eval)\n","full_data['Unnamed: 0'] = full_data['Unnamed: 0'].astype(str)\n","train_samples = []\n","dev_samples = []\n","test_samples = []\n","\n","for theme in themes:\n","  theme_df = full_data[full_data['Theme']==theme]\n","  n = len(theme_df)\n","  for i,theme_row in enumerate(theme_df.iterrows()):\n","    theme_row = theme_row[1]\n","    input = {\n","              'answers': {'answer_start':theme_row['Answer_start'],'text':theme_row['Answer_text']},\n","              'context':theme_row['Paragraph'],\n","              'id':theme_row['Unnamed: 0'],\n","              'question': theme_row['Question'],\n","              'title': theme_row['Theme']\n","          }\n","    if i<int(split[0]*n/sum(split)):\n","      train_samples.append(input)\n","    elif i<int((split[0]+split[1])*n/sum(split)):\n","      dev_samples.append(input)\n","    else:\n","      test_samples.append(input)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"616cL4tZVkC7"},"outputs":[],"source":["# dev_samples"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1B-E1-24_p3Y"},"outputs":[],"source":["#dataset for the trainer #dataset preprocessing to calculate the specific squadV2 metrics\n","\n","train_dataset2 = datasets.Dataset.from_list(train_samples)\n","val_dataset2 = datasets.Dataset.from_list(dev_samples)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IZoGzBIqct2h"},"outputs":[],"source":["#dataset for the trainer \n","\n","max_length = 384\n","stride = 128\n","\n","train_dataset = train_dataset2.map(\n","    preprocess_training_examples,\n","    batched=True,\n","    remove_columns=train_dataset2.column_names,\n",")\n","\n","train_dataset_eval=train_dataset2.map(\n","    preprocess_validation_examples,\n","    batched=True,\n","    remove_columns=train_dataset2.column_names,)\n","\n","validation_dataset = val_dataset2.map(\n","    preprocess_validation_examples,\n","    batched=True,\n","    remove_columns=val_dataset2.column_names,\n",")\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n","\n","metric = evaluate.load(\"squad_v2\")\n","model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FWdTZR63dl15"},"outputs":[],"source":["from transformers import TrainingArguments\n","\n","# Give the required training arguments\n","args = TrainingArguments(\n","    save_path,\n","    evaluation_strategy=\"epoch\",\n","    logging_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=batch_size,\n","    num_train_epochs=1,\n","    weight_decay=0.01,\n","    fp16=False,\n","    push_to_hub=False,\n","    logging_steps=100\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rIZMVj0Pdfx4"},"outputs":[],"source":["from transformers import Trainer\n","\n","trainer = Trainer(\n","    model=model,\n","    args=args,\n","    train_dataset=train_dataset,\n","    eval_dataset=train_dataset_eval,\n","    tokenizer=tokenizer,\n","    compute_metrics = compute_metrics\n",")\n","'''\n","#generate base results\n","import numpy as np\n","n_best=20\n","max_answer_length = 30\n","predictions,_,_ = trainer.predict(train_dataset)\n","start_logits, end_logits = predictions\n","metrics=compute_metrics(start_logits, end_logits, train_dataset, train_dataset2)\n","print(metrics)\n","df=pd.DataFrame(metrics, index=[0])'''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DcCZ1Ov6DcZQ"},"outputs":[],"source":["#Start Fine Tune\n","\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bpEgTumSY3tU"},"outputs":[],"source":["# trainer.push_to_hub(commit_message=\"Training complete\")"]},{"cell_type":"markdown","metadata":{"id":"NWq_y74E_f1E"},"source":["## Validation CSV Generation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hzAIvo6v-avR"},"outputs":[],"source":["if(mode=='ft+eval_same'):\n","  split=split_ft\n","elif(mode=='ft+eval_custom'):\n","  data_path=data_path_eval\n","  split=split_eval\n","elif(mode=='eval_only'):\n","  data_path=data_path_eval\n","  split=split_eval\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zgF6jPK08px2"},"outputs":[],"source":["from ast import literal_eval\n","\n","full_data = pd.read_csv(data_path)\n","id = []\n","for i in range(len(full_data)):\n","  id.append(i)\n","full_data['Unnamed: 0']=id\n","themes = full_data.Theme.unique()\n","full_data.Answer_start = full_data.Answer_start.apply(literal_eval)\n","full_data.Answer_text = full_data.Answer_text.apply(literal_eval)\n","full_data['Unnamed: 0'] = full_data['Unnamed: 0'].astype(str)\n","train_samples = []\n","dev_samples = []\n","test_samples = []\n","\n","for theme in themes:\n","  theme_df = full_data[full_data['Theme']==theme]\n","  n = len(theme_df)\n","  for i,theme_row in enumerate(theme_df.iterrows()):\n","    theme_row = theme_row[1]\n","    input = {\n","              #'Answer_possible': theme_row['Answer_possible'],\n","              'Answer_start':theme_row['Answer_start'],\n","              'Answer_Text':theme_row['Answer_text'],\n","              'Paragraph':theme_row['Paragraph'],\n","              'id':theme_row['Unnamed: 0'],\n","              'Question': theme_row['Question'],\n","              'Theme': theme_row['Theme']\n","          }\n","    if i<int(split[0]*n/sum(split)):\n","      train_samples.append(input)\n","    elif i<int((split[0]+split[1])*n/sum(split)):\n","      dev_samples.append(input)\n","    else:\n","      test_samples.append(input)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uKl2pN9emQ0P"},"outputs":[],"source":["'''\n","train_dataset2 = datasets.Dataset.from_list(train_samples)\n","val_dataset2 = datasets.Dataset.from_list(dev_samples)\n","\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XCRNZD7l6E8e"},"outputs":[],"source":["import pandas as pd\n","df_val = pd.DataFrame(dev_samples)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"amph6QkL6g0J"},"outputs":[],"source":["df_val.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k5PRxAxHtJRJ"},"outputs":[],"source":["val_csv_name=data_path.split('/')[-1][:-4]+'_'+str(split[0])+'%_validation.csv'\n","val_csv_name"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-ip7tD3_-jiD"},"outputs":[],"source":["df_val.to_csv(val_csv_name)"]},{"cell_type":"markdown","metadata":{"id":"NGmNU3FQvD8_"},"source":["## Evaluation Files(4 CSVs) Generation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C0zmsfumMW32"},"outputs":[],"source":["val_folder=val_csv_name[:-4]\n","val_folder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ef9ZYi4ov6ZM"},"outputs":[],"source":["import os\n","if not os.path.exists(val_folder): os.makedirs(val_folder)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TjrJ6vCVLUoE"},"outputs":[],"source":["df = pd.read_csv(val_csv_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TjgoPftnLUoF"},"outputs":[],"source":["df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qCQQWsnaLUoH"},"outputs":[],"source":["paras = df.Paragraph.unique()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mVv3glo4LUoI"},"outputs":[],"source":["df[df[\"Paragraph\"]==paras[0]].Theme[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7s51grJyLUoI"},"outputs":[],"source":["data = []\n","for i, para in enumerate(paras):\n","    data_dict = {}\n","    data_dict['id']=i+1\n","    data_dict['paragraph']=para\n","    data_dict['theme'] = df[df[\"Paragraph\"]==para].iloc[0].Theme\n","    data.append(data_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fTy9QXiOLUoJ"},"outputs":[],"source":["# data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tCIyBnkHLUoK"},"outputs":[],"source":["df2 = pd.DataFrame(data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sAkq-gwUx0kw"},"outputs":[],"source":["df2.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vXGdtnSBkDQN"},"outputs":[],"source":["df_theme=df2.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4tWS-YPrLUoL"},"outputs":[],"source":["input_para=val_folder+'/input_para.csv'\n","df2.to_csv(input_para, header=True, index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qg4FWtBDLUoM"},"outputs":[],"source":["data = []\n","for i in range(len(df.Question)):\n","    data_dict = dict()\n","    data_dict['id'] = i+1\n","    data_dict['question'] = df.Question[i]\n","    data_dict['theme'] = df.Theme[i]\n","    data.append(data_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"41Y6MDfALUoR"},"outputs":[],"source":["df2 = pd.DataFrame(data)\n","input_question=val_folder+'/input_question.csv'\n","df2.to_csv(input_question, header=True, index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-_YsKrZsLUob"},"outputs":[],"source":["data = []\n","for i in range(len(df.Question)):\n","    data_dict = dict()\n","    data_dict['question_id'] = i+1\n","    if(df.Answer_start[i]=='[]'):\n","     data_dict['paragraph_id'] = -1\n","    else:\n","     data_dict['paragraph_id']=df_theme[df_theme.paragraph==df.Paragraph[i]].index.tolist()[0]+1\n","    data_dict['answers'] = df.Answer_Text[i]\n","    data.append(data_dict)\n","df2 = pd.DataFrame(data)\n","ground_truth=val_folder+'/ground_truth.csv'\n","df2.to_csv(ground_truth, header=True, index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CCXQ4jPdLUod"},"outputs":[],"source":["data = []\n","for i in df.Theme.unique():\n","    data_dict = dict()\n","    start, end = (df.index[df['Theme']==i][[0,-1]]+1).tolist()\n","    data_dict[\"theme\"] = i\n","    data_dict[\"start\"] = start\n","    data_dict['end'] = end\n","    data.append(data_dict)\n","df2 = pd.DataFrame(data)\n","theme_interval=val_folder+'/theme_interval.csv'\n","df2.to_csv(theme_interval, header=True, index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GmsQ25G9aWlz"},"outputs":[],"source":["print(input_para+'\\n'+input_question+'\\n'+ground_truth+'\\n'+theme_interval+'\\n')"]},{"cell_type":"markdown","metadata":{"id":"ftljffNOzhJU"},"source":["# QA Evaluation"]},{"cell_type":"markdown","metadata":{"id":"tiwVWxCo3me-"},"source":["## Variable"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5tsPc_o6YyU-"},"outputs":[],"source":["ques_data_path = val_csv_name\n","theme_path = theme_interval\n","truth_path = ground_truth\n","threshold = 0.1"]},{"cell_type":"markdown","metadata":{"id":"bqa5lbm53uPP"},"source":["## Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B1oergIbAW2Z"},"outputs":[],"source":["import collections\n","import json\n","import pandas as pd\n","import re\n","import string\n","import timeit\n","from ast import literal_eval\n","!pip install transformers\n","from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n","import time"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l88RyWBNZIaH"},"outputs":[],"source":["questions = pd.read_csv(ques_data_path)\n","theme_intervals = pd.read_csv(theme_path)\n","truth =pd.read_csv(truth_path)"]},{"cell_type":"markdown","metadata":{"id":"I2AgPM1f4akG"},"source":["## Helpers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yCNnHfwtBAVP"},"outputs":[],"source":["def normalize_answer(s):\n","  \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n","  def remove_articles(text):\n","    regex = re.compile(r'\\b(a|an|the)\\b', re.UNICODE)\n","    return re.sub(regex, ' ', text)\n","  def white_space_fix(text):\n","    return ' '.join(text.split())\n","  def remove_punc(text):\n","    exclude = set(string.punctuation)\n","    return ''.join(ch for ch in text if ch not in exclude)\n","  def lower(text):\n","    return text.lower()\n","  return white_space_fix(remove_articles(remove_punc(lower(str(s)))))\n","\n","def get_tokens(s):\n","  if not s: return []\n","  return normalize_answer(s).split()\n","#gold_toks is the preprocessed text\n","def calc_f1(a_gold, a_pred):\n","  gold_toks = get_tokens(a_gold)\n","  pred_toks = get_tokens(a_pred)\n","  common = collections.Counter(gold_toks) & collections.Counter(pred_toks)\n","  num_same = sum(common.values())\n","  if len(gold_toks) == 0 or len(pred_toks) == 0:\n","    # If either is no-answer, then F1 is 1 if they agree, 0 otherwise\n","    return int(gold_toks == pred_toks)\n","  if num_same == 0:\n","    return 0\n","  precision = 1.0 * num_same / len(pred_toks)\n","  recall = 1.0 * num_same / len(gold_toks)\n","  f1 = (2 * precision * recall) / (precision + recall)\n","  return f1\n","\n","def calc_max_f1(predicted, ground_truths):\n","  max_f1 = 0\n","  for ground_truth in ground_truths:\n","    f1 = calc_f1(predicted, ground_truth)\n","    max_f1 = max(max_f1, f1)\n","  return max_f1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gcfCYAJNeeqr"},"outputs":[],"source":["def Average(lis):\n","  return sum(lis)/len(lis)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QctZ0wrdVHBi"},"outputs":[],"source":["def get_theme_model(theme):\n","  global_model = nlp\n","  return global_model\n","\n","def pred_theme_ans(questions,theme_model, pred_out):\n","  theme = questions[0][\"Theme\"]\n","  for question in questions:\n","    ans = {}\n","    ans[\"question_id\"] = question[\"id\"]\n","    result = theme_model(question=question['Question'], context=question['Paragraph'])\n","    score = result['score']\n","    answer = result['answer']\n","    if (score<threshold):\n","       ans[\"answers\"]= ''\n","    else:\n","      ans[\"answers\"]=answer\n","    pred_out.append(ans)\n"," \n","    "]},{"cell_type":"markdown","metadata":{"id":"SfxyLuek0sT-"},"source":["## Check point evaluation(Validation)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xTpEoWpD0sT_"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from tqdm import tqdm\n","import torch\n"]},{"cell_type":"markdown","metadata":{"id":"XPQpAq-fM-3t"},"source":["### Base eval"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M2isG67H0sT_"},"outputs":[],"source":["\n","#generate base results\n","\n","'''\n","By default, it generates results on base electra finetuned on squad V2 with model card: \"mrm8488/electra-small-finetuned-squadv2\".\n","If you want to check base results of a checkpoint change the qa_model_path with the custom checkpoint path\n","'''\n","\n","model_name = qa_model\n","m=model_name.split('/')[-1]+'validation'\n","nlp = pipeline(\"question-answering\", model = model_name)\n","  # All theme prediction.\n","questions = json.loads(pd.read_csv(ques_data_path).to_json(orient=\"records\"))\n","theme_intervals = json.loads(pd.read_csv(theme_path).to_json(orient=\"records\"))\n","pred_out = []\n","theme_inf_time = {}\n","execution_times = []\n","for theme_interval in tqdm(theme_intervals):\n","  theme_ques = questions[int(theme_interval[\"start\"]) - 1: int(theme_interval[\"end\"])]\n","  theme = theme_ques[0][\"Theme\"]\n","  # Load model fine-tuned for this theme.\n","  theme_model = get_theme_model(theme)\n","  execution_time = timeit.timeit(lambda: pred_theme_ans(theme_ques, theme_model, pred_out), number=1)\n","  execution_times.append(execution_time)\n","  theme_inf_time[theme_interval[\"theme\"]] = execution_time * 1000 # in milliseconds.\n","pred_df = pd.DataFrame.from_records(pred_out)\n","# Write prediction to a CSV file. Teams are required to submit this csv file.\n","pred_df.to_csv(f'{m}_pred.csv', index=False)\n","theme_inf_df = pd.DataFrame(list(theme_inf_time.items()),columns = ['theme','avg_inf_time']) \n","theme_inf_df.to_csv(f'{m}_inf_time.csv', index=False)\n","print(\"avg_inference_time:\",round(sum(execution_times)/len(questions),3)*1000)\n","pred_df.to_csv(f'{m}_pred.csv', index=False)\n","lst=theme_inf_df['avg_inf_time']\n","theme_int=pd.read_csv(theme_path)\n","theme_times = [ex_time/(theme_int['end'][i]-theme_int['start'][i]+1) for i,ex_time in enumerate(lst)]\n","metrics = {}\n","total_f1=0\n","pred = pd.read_csv(f'{m}_pred.csv')\n","truth = pd.read_csv(truth_path)\n","# truth.paragraph_id = truth.paragraph_id.apply(literal_eval)\n","truth.answers = truth.answers.apply(literal_eval)\n","questions = pd.read_csv(ques_data_path)\n","for idx in pred.index:\n","  q_id = pred.index[idx]\n","  q_rows = questions.loc[questions.index == q_id].iloc[-1]\n","  theme = q_rows[\"Theme\"]\n","  predicted_ans = pred[\"answers\"][idx]\n","  \n","  if theme not in metrics.keys():\n","    metrics[theme] = {\"true_positive\": 0, \"true_negative\": 0, \"total_predictions\": 0, \"f1_sum\": 0}\n","\n","  truth_row = truth.loc[truth.index == q_id].iloc[-1]\n","  if truth_row[\"answers\"] == [] and str(predicted_ans) =='nan':\n","    metrics[theme][\"true_negative\"] = metrics[theme][\"true_negative\"] + 1\n","    f1=1\n","  else:\n","    metrics[theme][\"true_positive\"] = metrics[theme][\"true_positive\"] + 1\n","    f1 = calc_max_f1(predicted_ans, truth_row[\"answers\"])\n","  metrics[theme][\"total_predictions\"] = metrics[theme][\"total_predictions\"] + 1\n","  metrics[theme][\"f1_sum\"] = metrics[theme][\"f1_sum\"] + f1\n","  total_f1+=f1\n","final_f1 = round(total_f1/len(questions),3)\n","theme_inf_df = pd.read_csv(f'{m}_inf_time.csv')\n","theme_inf_time = {theme:theme_inf_df[theme_inf_df['theme']==theme]['avg_inf_time'].tolist()[0] for theme in metrics}\n","no_of_themes=len(theme_inf_df)\n","# Final score.\n","inf_time_threshold = 1000.0 # milliseconds.\n","final_qa_score = 0.0\n","\n","for theme in metrics:\n","  inf_time_score = 1.0\n","  metric = metrics[theme]\n","  qa_score = metric[\"f1_sum\"] / metric[\"total_predictions\"]\n","  avg_inf_time = theme_inf_time[theme] / metric[\"total_predictions\"]\n","  if avg_inf_time > inf_time_threshold:\n","    inf_time_score = inf_time_threshold / avg_inf_time\n","  final_qa_score += 1/(no_of_themes) * inf_time_score * qa_score\n","print(final_f1,round(final_qa_score,3)*100,round(Average(theme_times),3),round(theme_times[len(theme_times)//2],3),round(max(theme_times),3))\n","metrics = [final_f1,round(final_qa_score,3)*100,round(Average(theme_times),3),round(theme_times[len(theme_times)//2],3),round(max(theme_times),3)]\n","df=pd.DataFrame(metrics).T\n","df.columns=['final_f1', 'qa_score','averege inf time', 'median inf time', 'max inf time']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7PHOfSrie7iV"},"outputs":[],"source":["df.head()"]},{"cell_type":"markdown","metadata":{"id":"r3XzsfDvNEZu"},"source":["### Checkpoint Eval"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mrBj7xv50sUD"},"outputs":[],"source":["import os \n","import numpy as np\n","j = 0\n","\n","if mode=='ft+eval_same':\n","  path = save_path\n","else:\n","  path = save_path_eval\n","\n","for i in os.listdir(path):\n","  if i == 'runs':\n","    continue\n","  m=i\n","  qa_model = i\n","  print(path+'/'+i)\n","  print(\"epoch =\", j)\n","  j += 1\n","  print(\"checkpoint = \", i)\n","  df1 = df.copy()\n","  ft_model_path=path+'/'+i\n","  nlp = pipeline(\"question-answering\", model = ft_model_path)\n","    # All theme prediction.\n","  questions = json.loads(pd.read_csv(ques_data_path).to_json(orient=\"records\"))\n","  theme_intervals = json.loads(pd.read_csv(theme_path).to_json(orient=\"records\"))\n","  pred_out = []\n","  theme_inf_time = {}\n","  execution_times = []\n","  for theme_interval in tqdm(theme_intervals):\n","    theme_ques = questions[int(theme_interval[\"start\"]) - 1: int(theme_interval[\"end\"])]\n","    theme = theme_ques[0][\"Theme\"]\n","    # Load model fine-tuned for this theme.\n","    theme_model = get_theme_model(theme)\n","    execution_time = timeit.timeit(lambda: pred_theme_ans(theme_ques, theme_model, pred_out), number=1)\n","    execution_times.append(execution_time)\n","    theme_inf_time[theme_interval[\"theme\"]] = execution_time * 1000 # in milliseconds.\n","  pred_df = pd.DataFrame.from_records(pred_out)\n","  # Write prediction to a CSV file. Teams are required to submit this csv file.\n","  pred_df.to_csv(f'{m}_pred.csv', index=False)\n","  theme_inf_df = pd.DataFrame(list(theme_inf_time.items()),columns = ['theme','avg_inf_time']) \n","  theme_inf_df.to_csv(f'{m}_inf_time.csv', index=False)\n","  print(\"avg_inference_time:\",round(sum(execution_times)/len(questions),3)*1000)\n","  pred_df.to_csv(f'{m}_pred.csv', index=False)\n","  lst=theme_inf_df['avg_inf_time']\n","  theme_int=pd.read_csv(theme_path)\n","  theme_times = [ex_time/(theme_int['end'][i]-theme_int['start'][i]+1) for i,ex_time in enumerate(lst)]\n","  metrics = {}\n","  total_f1=0\n","  pred = pd.read_csv(f'{m}_pred.csv')\n","  truth = pd.read_csv(truth_path)\n","  # truth.paragraph_id = truth.paragraph_id.apply(literal_eval)\n","  truth.answers = truth.answers.apply(literal_eval)\n","  questions = pd.read_csv(ques_data_path)\n","  for idx in pred.index:\n","    q_id = pred.index[idx]\n","    q_rows = questions.loc[questions.index == q_id].iloc[-1]\n","    theme = q_rows[\"Theme\"]\n","    predicted_ans = pred[\"answers\"][idx]\n","    \n","    if theme not in metrics.keys():\n","      metrics[theme] = {\"true_positive\": 0, \"true_negative\": 0, \"total_predictions\": 0, \"f1_sum\": 0}\n","\n","    truth_row = truth.loc[truth.index == q_id].iloc[-1]\n","    if truth_row[\"answers\"] == [] and str(predicted_ans) =='nan':\n","      metrics[theme][\"true_negative\"] = metrics[theme][\"true_negative\"] + 1\n","      f1=1\n","    else:\n","      metrics[theme][\"true_positive\"] = metrics[theme][\"true_positive\"] + 1\n","      f1 = calc_max_f1(predicted_ans, truth_row[\"answers\"])\n","    metrics[theme][\"total_predictions\"] = metrics[theme][\"total_predictions\"] + 1\n","    metrics[theme][\"f1_sum\"] = metrics[theme][\"f1_sum\"] + f1\n","    total_f1+=f1\n","  final_f1 = round(total_f1/len(questions),3)\n","  theme_inf_df = pd.read_csv(f'{m}_inf_time.csv')\n","  theme_inf_time = {theme:theme_inf_df[theme_inf_df['theme']==theme]['avg_inf_time'].tolist()[0] for theme in metrics}\n","  no_of_themes=len(theme_inf_df)\n","  # Final score.\n","  inf_time_threshold = 1000.0 # milliseconds.\n","  final_qa_score = 0.0\n","\n","  for theme in metrics:\n","    inf_time_score = 1.0\n","    metric = metrics[theme]\n","    qa_score = metric[\"f1_sum\"] / metric[\"total_predictions\"]\n","    avg_inf_time = theme_inf_time[theme] / metric[\"total_predictions\"]\n","    if avg_inf_time > inf_time_threshold:\n","      inf_time_score = inf_time_threshold / avg_inf_time\n","    final_qa_score += 1/(no_of_themes) * inf_time_score * qa_score\n","  print(final_f1,round(final_qa_score,3)*100,round(Average(theme_times),3),round(theme_times[len(theme_times)//2],3),round(max(theme_times),3))\n","  metrics = [final_f1,round(final_qa_score,3)*100,round(Average(theme_times),3),round(theme_times[len(theme_times)//2],3),round(max(theme_times),3)]\n","  df2 = pd.DataFrame(metrics).T\n","  df2.columns=['final_f1', 'qa_score','averege inf time', 'median inf time', 'max inf time']\n","  df = pd.concat([df1, df2], axis=0)\n","  print(df)\n","  print(\"\\n\\n\\n===========================================\\n\\n\\n\")\n","\n","  print(metrics)\n","\n","  print(\"\\n\\n\\n===========================================\\n\\n\\n\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y0xCVZux4oLg"},"outputs":[],"source":["df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hjXSodfe4ZPd"},"outputs":[],"source":["out=path.split('/')[-1]+'_final_eval.csv'\n","df.to_csv(out)\n","out #Evaulation results path"]}],"metadata":{"colab":{"collapsed_sections":["JJGmY-7m_G7P","IQ1u-0zgeoiC","VAim9LD1LrKu","Dz5a0nvgae1n","6ePrJiCIdyVm","NWq_y74E_f1E","NGmNU3FQvD8_","tiwVWxCo3me-","bqa5lbm53uPP","I2AgPM1f4akG"],"private_outputs":true,"provenance":[{"file_id":"1lLDqrW3w-i0Ky6aYsNtpFATqljI5erQa","timestamp":1675783404872},{"file_id":"1VoIMlMduSeZBNaefnl0pUEzMSMaqdFZ_","timestamp":1675775887329}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.10"},"vscode":{"interpreter":{"hash":"73d41fdac83fc891b88f8c6d970584d21b54ca61e1bc00d779e118ba98b55913"}}},"nbformat":4,"nbformat_minor":0}
