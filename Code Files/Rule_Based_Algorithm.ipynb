{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CxByfhyEpsN"
      },
      "source": [
        "#Initialize Cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbnvZNjU4ZOH",
        "outputId": "6194d416-5ccb-4b89-f8ad-39498062aa86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.8/dist-packages (2.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install inflect\n",
        "import inflect\n",
        "p = inflect.engine()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "1daec11edb084841919b22747768a533",
            "b1bf3fda407c43288aba027fac90234b",
            "bcc222323be74b9587877376a4ee0eed",
            "dd9cedb538714a71a597a086db1dabb4",
            "538228c38bc84854be429fae408311b6",
            "94716b8ff9a64ff5be84d4be23955506",
            "6c7b4be337df404b948c5ed2b302958f",
            "91e8312fc4ca4b578dd6734ed8c84782",
            "f7d41a7fcfb845aaa9f4eb2a3d758e00",
            "8bf55f9d210943ea8412a8eb1e1baf98",
            "3d688a7dddf34b63ba70d68eaeb228a5"
          ],
          "height": 1000
        },
        "id": "SIr2ngPsJEmN",
        "outputId": "650b4ef8-1301-4c4f-a257-51b2fff831dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting stanza\n",
            "  Downloading stanza-1.4.2-py3-none-any.whl (691 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m691.3/691.3 KB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting unidecode\n",
            "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 KB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from stanza) (1.13.1+cu116)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from stanza) (4.64.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.8/dist-packages (from stanza) (3.19.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from stanza) (2.25.1)\n",
            "Collecting emoji\n",
            "  Downloading emoji-2.2.0.tar.gz (240 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.9/240.9 KB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from stanza) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from stanza) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.3.0->stanza) (4.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->stanza) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->stanza) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->stanza) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->stanza) (4.0.0)\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-2.2.0-py3-none-any.whl size=234926 sha256=13504ec08886475eeef120a8da73e848c3778f7971dcdcc92a236d003f868796\n",
            "  Stored in directory: /root/.cache/pip/wheels/86/62/9e/a6b27a681abcde69970dbc0326ff51955f3beac72f15696984\n",
            "Successfully built emoji\n",
            "Installing collected packages: unidecode, emoji, stanza\n",
            "Successfully installed emoji-2.2.0 stanza-1.4.2 unidecode-1.3.6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:stanza:Installing CoreNLP package into ./corenlp\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading https://huggingface.co/stanfordnlp/CoreNLP/resolve/main/stanford-corenlp-latest.zip:   0%|        …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1daec11edb084841919b22747768a533"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:stanza:For customized installation location, please set the `CORENLP_HOME` environment variable to the location of the installation. In Unix, this is done with `export CORENLP_HOME=./corenlp`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "build.xml\t\t\t\t  LIBRARY-LICENSES\n",
            "corenlp.sh\t\t\t\t  LICENSE.txt\n",
            "CoreNLP-to-HTML.xsl\t\t\t  Makefile\n",
            "ejml-core-0.39.jar\t\t\t  patterns\n",
            "ejml-core-0.39-sources.jar\t\t  pom-java-11.xml\n",
            "ejml-ddense-0.39.jar\t\t\t  pom-java-17.xml\n",
            "ejml-ddense-0.39-sources.jar\t\t  pom.xml\n",
            "ejml-simple-0.39.jar\t\t\t  protobuf-java-3.19.2.jar\n",
            "ejml-simple-0.39-sources.jar\t\t  README.txt\n",
            "input.txt\t\t\t\t  RESOURCE-LICENSES\n",
            "input.txt.out\t\t\t\t  sample-project-pom.xml\n",
            "input.txt.xml\t\t\t\t  SemgrexDemo.java\n",
            "istack-commons-runtime-3.0.7.jar\t  ShiftReduceDemo.java\n",
            "istack-commons-runtime-3.0.7-sources.jar  slf4j-api.jar\n",
            "javax.activation-api-1.2.0.jar\t\t  slf4j-simple.jar\n",
            "javax.activation-api-1.2.0-sources.jar\t  stanford-corenlp-4.5.1.jar\n",
            "javax.json-api-1.0-sources.jar\t\t  stanford-corenlp-4.5.1-javadoc.jar\n",
            "javax.json.jar\t\t\t\t  stanford-corenlp-4.5.1-models.jar\n",
            "jaxb-api-2.4.0-b180830.0359.jar\t\t  stanford-corenlp-4.5.1-sources.jar\n",
            "jaxb-api-2.4.0-b180830.0359-sources.jar   StanfordCoreNlpDemo.java\n",
            "jaxb-impl-2.4.0-b180830.0438.jar\t  StanfordDependenciesManual.pdf\n",
            "jaxb-impl-2.4.0-b180830.0438-sources.jar  sutime\n",
            "joda-time-2.10.5-sources.jar\t\t  tokensregex\n",
            "joda-time.jar\t\t\t\t  xom-1.3.7-sources.jar\n",
            "jollyday-0.4.9-sources.jar\t\t  xom.jar\n",
            "jollyday.jar\n"
          ]
        }
      ],
      "source": [
        "# Initialize Stanford NLP\n",
        "!pip install stanza unidecode\n",
        "\n",
        "import unidecode\n",
        "import stanza\n",
        "from itertools import permutations\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import re\n",
        "from stanza.server import CoreNLPClient\n",
        "import os\n",
        "\n",
        "corenlp_dir = './corenlp'\n",
        "stanza.install_corenlp(dir=corenlp_dir)\n",
        "os.environ[\"CORENLP_HOME\"] = corenlp_dir\n",
        "!ls $CORENLP_HOME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5L0QQAhDzMA",
        "outputId": "63f86b51-73d7-4c5c-d3a1-4428c2647f6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:stanza:Writing properties to tmp file: corenlp_server-bc5d857426654a81.props\n",
            "INFO:stanza:Starting server with command: java -Xmx4G -cp ./corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 60000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-bc5d857426654a81.props -annotators tokenize,ssplit,pos,lemma,ner,depparse -preload -outputFormat serialized\n"
          ]
        }
      ],
      "source": [
        "client = CoreNLPClient(\n",
        "    annotators=['tokenize','ssplit', 'pos', 'lemma', 'ner', 'depparse'], \n",
        "    memory='4G', \n",
        "    endpoint='http://localhost:9001',\n",
        "    be_quiet=True)\n",
        "client.start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFFEjvRAKQEO",
        "outputId": "a54a0dc5-4ba1-416b-cd6a-ff91a38437d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8q8qf2dBzKDu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhqZv6IUE0te"
      },
      "source": [
        "#Import Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsEqgoYoKQxQ"
      },
      "outputs": [],
      "source": [
        "para_data_path = '/content/drive/MyDrive/Assets/Processed Dataset/Final_eval_10000/input_paragraph_train_2.csv'\n",
        "ques_data_path = '/content/drive/MyDrive/Assets/Processed Dataset/Final_eval_10000/input_questions_train_10k.csv'\n",
        "theme_path = '/content/drive/MyDrive/Assets/Processed Dataset/Final_eval_10000/theme_interval_train_10k.csv'\n",
        "ground_truth_path = '/content/drive/MyDrive/Assets/Processed Dataset/Final_eval_10000/ground_truth_train_10k.csv'\n",
        "para_df = pd.read_csv(para_data_path)\n",
        "ques_df = pd.read_csv(ques_data_path)\n",
        "theme_df = pd.read_csv(theme_path)\n",
        "ground_truth_df = pd.read_csv(ground_truth_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tyVjoas0zMIv"
      },
      "outputs": [],
      "source": [
        "def paraLemma(df):\n",
        "  data = dict()\n",
        "  paragraphs = df.paragraph.tolist()\n",
        "  lemma = []\n",
        "  pos = []\n",
        "  ner = []\n",
        "  for para in paragraphs:\n",
        "    lemma_str = ''\n",
        "    pos_str = ''\n",
        "    ner_str = ''\n",
        "    document = client.annotate(para)\n",
        "    for i, sent in enumerate(document.sentence):\n",
        "      for t in sent.token:\n",
        "        pos_str+=t.pos+' '\n",
        "        ner_str+=t.ner+' '\n",
        "        lemma_str+=t.lemma+' '\n",
        "    lemma.append(lemma_str)\n",
        "    pos.append(pos_str)\n",
        "    ner.append(ner_str)\n",
        "  data['paragraph'] = paragraphs\n",
        "  data['lemma'] = lemma\n",
        "  data['pos'] = pos\n",
        "  data['ner'] = ner\n",
        "  new_df = pd.DataFrame(data)\n",
        "  new_df.to_csv('core_nlp_para.csv')\n",
        "#paraLemma(para_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6n0ABfkzbxM"
      },
      "outputs": [],
      "source": [
        "lemma_path = '/content/drive/MyDrive/Assets/Processed Dataset/Final_eval_10000/core_nlp_para.csv'\n",
        "lemma_df = pd.read_csv(lemma_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gL5uSDuvE60z"
      },
      "source": [
        "#Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5nT3Vm2UXNk"
      },
      "outputs": [],
      "source": [
        "def apostrophe(question, paragraph):\n",
        "  context = paragraph\n",
        "  string = re.findall('\"([^\"]*)\"', question) + re.findall(\"'([^']*)'\", question)\n",
        "  return string\n",
        "\n",
        "def abbr(question):\n",
        "  string = re.findall(r'(?:[A-Z]\\.)+',question) + re.findall(r'\\b(?:[A-Z]){2,}', question)\n",
        "  return string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09kwDuczNDmF"
      },
      "outputs": [],
      "source": [
        "def rule_based(question, paragraph, lemma_df):\n",
        "  # Check for Abbreviation\n",
        "  abbreviations = abbr(question)\n",
        "  if len(abbreviations) > 0:\n",
        "    for abbreviation in abbreviations:\n",
        "      question = question.replace(abbreviation,'')\n",
        "  question = question.lower()\n",
        "  document = client.annotate(question)\n",
        "  context = paragraph\n",
        "  pos = []\n",
        "  ner = []\n",
        "  words = []\n",
        "  normalized_ner = []\n",
        "  coarse_ner = []\n",
        "  lemma = []\n",
        "  check_words = ['P1Y', 'PXY', 'PRESENT', 'PREV', 'NEXT', 'FUTURE', 'OFFSET', 'IMMEDIATE', 'THIS', 'PT1S', 'INTERSECT', 'P1D', 'P1M', '1985', 'P1W', 'TMO', 'TDT', 'PAST', 'TNI']\n",
        "  flag = 0\n",
        "  for i, sent in enumerate(document.sentence):\n",
        "    for t in sent.token:\n",
        "      words.append(t.word)\n",
        "      pos.append(t.pos)\n",
        "      ner.append(t.ner)\n",
        "      normalized_ner.append(t.normalizedNER)\n",
        "      lemma.append(t.lemma)\n",
        "      coarse_ner.append(t.coarseNER)\n",
        "  # Quotes\n",
        "  if question.count('\"')>1 or question.count(\"'\")>1:\n",
        "    narrow = []\n",
        "    answer = apostrophe(question, context)\n",
        "    for para in context:\n",
        "      para_low=para.lower()\n",
        "      if any(ans in para_low for ans in answer):\n",
        "        narrow.append(para)\n",
        "    if len(narrow)>0:\n",
        "      context = list(set(narrow))\n",
        "      flag = 1\n",
        "    else:\n",
        "      context = paragraph\n",
        "  # NER\n",
        "  if flag == 0:\n",
        "    narrow = []\n",
        "    if 'DATE' in ner:\n",
        "      ner_indices = [idx for idx, value in enumerate(ner) if value == 'DATE']\n",
        "      for ner_index in ner_indices:\n",
        "        if not any(check_word in normalized_ner[ner_index] for check_word in check_words):\n",
        "          word = words[ner_index]\n",
        "          for para in context:\n",
        "            para_low=para.lower()\n",
        "            if word in para_low:\n",
        "              narrow.append(para)\n",
        "    if 'TIME' in ner:\n",
        "      ner_indices = [idx for idx, value in enumerate(ner) if value == 'TIME']\n",
        "      for ner_index in ner_indices:\n",
        "        if not any(check_word in normalized_ner[ner_index] for check_word in check_words):\n",
        "          word = words[ner_index]\n",
        "          for para in context:\n",
        "            para_low=para.lower()\n",
        "            if word in para_low:\n",
        "              narrow.append(para)\n",
        "    if 'LOCATION' in ner: #ner -> coarse_ner\n",
        "      ner_indices = [idx for idx, value in enumerate(ner) if value == 'LOCATION'] #ner -> coarse_ner\n",
        "      for ner_index in ner_indices:\n",
        "        word = words[ner_index]\n",
        "        for para in context:\n",
        "          para_low=para.lower()\n",
        "          if word in para_low:\n",
        "            narrow.append(para)\n",
        "    if 'MONEY' in ner:\n",
        "      ner_indices = [idx for idx, value in enumerate(ner) if value == 'MONEY']\n",
        "      for ner_index in ner_indices:\n",
        "        word = words[ner_index]\n",
        "        for para in context:\n",
        "          para_low=para.lower()\n",
        "          if word in para_low:\n",
        "            narrow.append(para)\n",
        "    if 'ORGANIZATION' in ner:\n",
        "      ner_indices = [idx for idx, value in enumerate(ner) if value == 'ORGANIZATION']\n",
        "      for ner_index in ner_indices:\n",
        "        word = words[ner_index]\n",
        "        for para in context:\n",
        "          para_low=para.lower()\n",
        "          if word in para_low:\n",
        "            narrow.append(para)\n",
        "    if len(narrow)>0:\n",
        "      context = list(set(narrow))\n",
        "      flag = 1\n",
        "    else:\n",
        "      context = paragraph\n",
        "  # PROPER NOUN\n",
        "  if flag == 0 or len(context) == len(paragraph):\n",
        "    for ind in range(-2, -len(pos), -1):\n",
        "      if pos[ind] in ['NNP', 'NNPS']:\n",
        "        word = words[ind]\n",
        "        for para in context:\n",
        "          para_low=para.lower()\n",
        "          if word in para_low:\n",
        "            narrow.append(para)\n",
        "      else:\n",
        "        break\n",
        "    if len(narrow)>0:\n",
        "      context = list(set(narrow))\n",
        "      flag = 1\n",
        "    else:\n",
        "      context = paragraph\n",
        "  # COMMON NOUN\n",
        "  if flag == 0 or len(context)==len(paragraph):\n",
        "    narrow = []\n",
        "    if 'NN' in pos:\n",
        "      pos_indices = [idx for idx, value in enumerate(pos) if value == 'NN']\n",
        "      for pos_index in pos_indices:\n",
        "        word = words[pos_index]\n",
        "        if p.singular_noun(word):\n",
        "          plural_word = p.plural_noun(word)\n",
        "        else:\n",
        "          plural_word = word\n",
        "        for para in context:\n",
        "          para_low=para.lower()\n",
        "          if word in para_low or plural_word in para_low:\n",
        "            narrow.append(para)\n",
        "    if 'NNS' in pos:\n",
        "      pos_indices = [idx for idx, value in enumerate(pos) if value == 'NNS']\n",
        "      for pos_index in pos_indices:\n",
        "        word = words[pos_index]\n",
        "        if p.singular_noun(word):\n",
        "          singular_word = p.singular_noun(word)\n",
        "        else:\n",
        "          singular_word = word\n",
        "        for para in context:\n",
        "          para_low=para.lower()\n",
        "          if word in para_low or singular_word in para_low:\n",
        "            narrow.append(para)\n",
        "    if len(narrow)>0:\n",
        "      context = list(set(narrow))\n",
        "      flag = 1\n",
        "    else:\n",
        "      context = paragraph\n",
        "  #VERB\n",
        "  lemmatized_para = lemma_df[lemma_df.paragraph.isin(context)].lemma.tolist()\n",
        "  if flag==0 or len(context)==len(paragraph):\n",
        "    narrow = []\n",
        "    if 'VB' in pos or 'VBP' in pos or 'VBZ' in pos or 'VBN' in pos or 'VBG' in pos or 'VBD' in pos:\n",
        "      pos_indices = [idx for idx, value in enumerate(pos) if value == 'VB' or value == 'VBP' or value == 'VBZ' or value == 'VBN' or value == 'VBG' or value == 'VBD']\n",
        "      for pos_index in pos_indices:\n",
        "        word = lemma[pos_index]\n",
        "        for para_id,para in enumerate(lemmatized_para):\n",
        "          para_low=para.lower()\n",
        "          if word in para_low:\n",
        "            narrow.append(context[para_id])\n",
        "    if len(narrow)>0:\n",
        "      context = list(set(narrow))\n",
        "      flag = 1\n",
        "    else:\n",
        "      context = paragraph\n",
        "  return context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln3YjGd1Fb_i"
      },
      "source": [
        "#Main Test Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cx6fzcvpK5Q1",
        "outputId": "d93a1131-f701-4982-ada1-ba9dfab6ea84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:stanza:Starting server with command: java -Xmx4G -cp ./corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 60000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-bc5d857426654a81.props -annotators tokenize,ssplit,pos,lemma,ner,depparse -preload -outputFormat serialized\n",
            "100%|██████████| 46/46 [09:29<00:00, 12.38s/it]\n"
          ]
        }
      ],
      "source": [
        "wrong_pred_list = []\n",
        "accuracy_data = []\n",
        "acc_total = 0\n",
        "blank_total = 0\n",
        "no_narrow_total = 0\n",
        "wrong_total = 0\n",
        "length_of_narrow = []\n",
        "length_of_narrow_perc = []\n",
        "for theme in tqdm(theme_df.theme):\n",
        "  accuracy_dict = dict()\n",
        "  accuracy_dict['theme'] = theme\n",
        "  questions = ques_df[ques_df.theme==theme].question.tolist()\n",
        "  acc = 0\n",
        "  blank_pred = 0\n",
        "  no_narrow = 0\n",
        "  wrong_pred = 0\n",
        "  for question in questions:\n",
        "    real_para = ground_truth_df[ground_truth_df.question_id == ques_df[ques_df.question == question].iloc[0,0]].iloc[0, -1] + 1\n",
        "    real_ans = ground_truth_df[ground_truth_df.question_id == ques_df[ques_df.question == question].iloc[0,0]].iloc[0, -2]\n",
        "    paras = para_df[para_df.theme==theme].paragraph.tolist()\n",
        "    max_thres = len(paras)/3\n",
        "    min_thres = len(paras)/6\n",
        "    trim_question = unidecode.unidecode(question)\n",
        "    lemmatized_para = lemma_df[lemma_df.paragraph.isin(paras)]\n",
        "    ans = rule_based(trim_question, paras, lemmatized_para)\n",
        "    length_of_narrow.append(len(ans))\n",
        "    length_of_narrow_perc.append(len(ans)/len(paras))\n",
        "    pred_para = para_df[para_df.paragraph.isin(ans)].id.tolist()\n",
        "    if len(pred_para) == 0 and not real_ans=='[]':\n",
        "      blank_pred+=1\n",
        "      blank_total+=1\n",
        "    elif len(pred_para) == len(paras) and not real_ans=='[]':\n",
        "      no_narrow+=1\n",
        "      no_narrow_total+=1\n",
        "    elif real_para in pred_para or real_ans=='[]':\n",
        "      acc+=1\n",
        "      acc_total+=1\n",
        "    else:\n",
        "      wrong_pred_list.append(question)\n",
        "      wrong_pred+=1\n",
        "      wrong_total+=1\n",
        "  acc = acc/len(questions)\n",
        "  blank_pred = blank_pred/len(questions)\n",
        "  accuracy_dict['acc'] = acc\n",
        "  accuracy_dict['blank_pred'] = blank_pred\n",
        "  accuracy_data.append(accuracy_dict)\n",
        "  acc_total, no_narrow_total, blank_total, wrong_total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GuTQpzqvBmZd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58466df0-c4e5-46a3-d858-a70e4783ea49"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9437, 131, 0, 432)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "acc_total, no_narrow_total, blank_total, wrong_total"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ques_df['length_of_narrow'] = length_of_narrow\n",
        "ques_df['length_of_narrow_perc'] = length_of_narrow_perc"
      ],
      "metadata": {
        "id": "xpNazfJlXW2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQ1iJsAYArVk"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv('/content/drive/MyDrive/Assets/train_data.csv')\n",
        "train_data[train_data.Question.isin(wrong_pred_list)].to_csv('./wrong_pred_424.csv', index=False, header=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBtoUtWgonIx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7e47b1e-01ff-4f18-f15b-399ff6bf1e8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word: \"What\"\n",
            "pos: \"WDT\"\n",
            "value: \"What\"\n",
            "before: \"\"\n",
            "after: \" \"\n",
            "originalText: \"What\"\n",
            "ner: \"O\"\n",
            "lemma: \"what\"\n",
            "beginChar: 0\n",
            "endChar: 4\n",
            "tokenBeginIndex: 0\n",
            "tokenEndIndex: 1\n",
            "hasXmlContext: false\n",
            "isNewline: false\n",
            "coarseNER: \"O\"\n",
            "fineGrainedNER: \"O\"\n",
            "nerLabelProbs: \"O=0.9999708045725951\"\n",
            "\n",
            "word: \"movie\"\n",
            "pos: \"NN\"\n",
            "value: \"movie\"\n",
            "before: \" \"\n",
            "after: \" \"\n",
            "originalText: \"movie\"\n",
            "ner: \"O\"\n",
            "lemma: \"movie\"\n",
            "beginChar: 5\n",
            "endChar: 10\n",
            "tokenBeginIndex: 1\n",
            "tokenEndIndex: 2\n",
            "hasXmlContext: false\n",
            "isNewline: false\n",
            "coarseNER: \"O\"\n",
            "fineGrainedNER: \"O\"\n",
            "nerLabelProbs: \"O=0.9997124582603977\"\n",
            "\n",
            "word: \"did\"\n",
            "pos: \"VBD\"\n",
            "value: \"did\"\n",
            "before: \" \"\n",
            "after: \" \"\n",
            "originalText: \"did\"\n",
            "ner: \"O\"\n",
            "lemma: \"do\"\n",
            "beginChar: 11\n",
            "endChar: 14\n",
            "tokenBeginIndex: 2\n",
            "tokenEndIndex: 3\n",
            "hasXmlContext: false\n",
            "isNewline: false\n",
            "coarseNER: \"O\"\n",
            "fineGrainedNER: \"O\"\n",
            "nerLabelProbs: \"O=0.9999300453298651\"\n",
            "\n",
            "word: \"Beyonce\"\n",
            "pos: \"NNP\"\n",
            "value: \"Beyonce\"\n",
            "before: \" \"\n",
            "after: \" \"\n",
            "originalText: \"Beyonce\"\n",
            "ner: \"PERSON\"\n",
            "lemma: \"Beyonce\"\n",
            "beginChar: 15\n",
            "endChar: 22\n",
            "tokenBeginIndex: 3\n",
            "tokenEndIndex: 4\n",
            "hasXmlContext: false\n",
            "isNewline: false\n",
            "coarseNER: \"PERSON\"\n",
            "fineGrainedNER: \"PERSON\"\n",
            "entityMentionIndex: 0\n",
            "nerLabelProbs: \"PERSON=0.7482696256713075\"\n",
            "\n",
            "word: \"act\"\n",
            "pos: \"VB\"\n",
            "value: \"act\"\n",
            "before: \" \"\n",
            "after: \" \"\n",
            "originalText: \"act\"\n",
            "ner: \"O\"\n",
            "lemma: \"act\"\n",
            "beginChar: 23\n",
            "endChar: 26\n",
            "tokenBeginIndex: 4\n",
            "tokenEndIndex: 5\n",
            "hasXmlContext: false\n",
            "isNewline: false\n",
            "coarseNER: \"O\"\n",
            "fineGrainedNER: \"O\"\n",
            "nerLabelProbs: \"O=0.9994107709306428\"\n",
            "\n",
            "word: \"in\"\n",
            "pos: \"IN\"\n",
            "value: \"in\"\n",
            "before: \" \"\n",
            "after: \" \"\n",
            "originalText: \"in\"\n",
            "ner: \"O\"\n",
            "lemma: \"in\"\n",
            "beginChar: 27\n",
            "endChar: 29\n",
            "tokenBeginIndex: 5\n",
            "tokenEndIndex: 6\n",
            "hasXmlContext: false\n",
            "isNewline: false\n",
            "coarseNER: \"O\"\n",
            "fineGrainedNER: \"O\"\n",
            "nerLabelProbs: \"O=0.9999977951629125\"\n",
            "\n",
            "word: \"2006\"\n",
            "pos: \"CD\"\n",
            "value: \"2006\"\n",
            "before: \" \"\n",
            "after: \"\"\n",
            "originalText: \"2006\"\n",
            "ner: \"DATE\"\n",
            "normalizedNER: \"2006\"\n",
            "lemma: \"2006\"\n",
            "beginChar: 30\n",
            "endChar: 34\n",
            "tokenBeginIndex: 6\n",
            "tokenEndIndex: 7\n",
            "timexValue {\n",
            "  value: \"2006\"\n",
            "  text: \"2006\"\n",
            "  type: \"DATE\"\n",
            "  tid: \"t1\"\n",
            "}\n",
            "hasXmlContext: false\n",
            "isNewline: false\n",
            "coarseNER: \"DATE\"\n",
            "fineGrainedNER: \"DATE\"\n",
            "entityMentionIndex: 1\n",
            "nerLabelProbs: \"DATE=0.9641158201102344\"\n",
            "numericValue: 2006\n",
            "numericType: \"NUMBER\"\n",
            "numericCompositeValue: 2006\n",
            "numericCompositeType: \"NUMBER\"\n",
            "\n",
            "word: \"?\"\n",
            "pos: \".\"\n",
            "value: \"?\"\n",
            "before: \"\"\n",
            "after: \"\"\n",
            "originalText: \"?\"\n",
            "ner: \"O\"\n",
            "lemma: \"?\"\n",
            "beginChar: 34\n",
            "endChar: 35\n",
            "tokenBeginIndex: 7\n",
            "tokenEndIndex: 8\n",
            "hasXmlContext: false\n",
            "isNewline: false\n",
            "coarseNER: \"O\"\n",
            "fineGrainedNER: \"O\"\n",
            "nerLabelProbs: \"O=0.9999950408777535\"\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test = client.annotate('What movie did Beyonce act in 2006?')\n",
        "for sen in test.sentence:\n",
        "  for tok in sen.token:\n",
        "    print(tok)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6IFXWJ-Yad9h"
      },
      "outputs": [],
      "source": [
        "client.stop()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "2CxByfhyEpsN"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1daec11edb084841919b22747768a533": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b1bf3fda407c43288aba027fac90234b",
              "IPY_MODEL_bcc222323be74b9587877376a4ee0eed",
              "IPY_MODEL_dd9cedb538714a71a597a086db1dabb4"
            ],
            "layout": "IPY_MODEL_538228c38bc84854be429fae408311b6"
          }
        },
        "b1bf3fda407c43288aba027fac90234b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94716b8ff9a64ff5be84d4be23955506",
            "placeholder": "​",
            "style": "IPY_MODEL_6c7b4be337df404b948c5ed2b302958f",
            "value": "Downloading https://huggingface.co/stanfordnlp/CoreNLP/resolve/main/stanford-corenlp-latest.zip: 100%"
          }
        },
        "bcc222323be74b9587877376a4ee0eed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91e8312fc4ca4b578dd6734ed8c84782",
            "max": 505225173,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f7d41a7fcfb845aaa9f4eb2a3d758e00",
            "value": 505225173
          }
        },
        "dd9cedb538714a71a597a086db1dabb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bf55f9d210943ea8412a8eb1e1baf98",
            "placeholder": "​",
            "style": "IPY_MODEL_3d688a7dddf34b63ba70d68eaeb228a5",
            "value": " 505M/505M [00:23&lt;00:00, 23.0MB/s]"
          }
        },
        "538228c38bc84854be429fae408311b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94716b8ff9a64ff5be84d4be23955506": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c7b4be337df404b948c5ed2b302958f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91e8312fc4ca4b578dd6734ed8c84782": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7d41a7fcfb845aaa9f4eb2a3d758e00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8bf55f9d210943ea8412a8eb1e1baf98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d688a7dddf34b63ba70d68eaeb228a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}